{
  "createdAt": "2025-10-16T23:18:04.754Z",
  "updatedAt": "2025-10-27T14:53:21.000Z",
  "id": "Hg91NZVyqdB46nko",
  "name": "@MAIN_TEXT_GENERATION",
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "o3-mini-2025-01-31",
          "mode": "list",
          "cachedResultName": "o3-mini-2025-01-31"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        448,
        448
      ],
      "id": "9a44dd0c-0ec2-49bf-862f-1b7fdf3feb66",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "VYXpJ372t4VzzgvC",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"imageStyle\": \"normalized-string\",\n  \"scenes\": [\n    {\n      \"index\": 0,\n      \"introduction\": true,\n      \"description\": \"detailed image prompt for the scene, aligned with imageStyle\",\n      \"paragraphs\": [\n        { \"id\": 0, \"text\": \"...\", \"voiceId\":\"...\" },\n        { \"id\": 1, \"text\": \"...\", \"voiceId\":\"...\" }\n      ]\n    }\n  ]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        864,
        464
      ],
      "id": "c1d9ae8c-3602-4417-b85c-d1515cc7781c",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "options": {
          "prompt": "Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "typeVersion": 1,
      "position": [
        816,
        240
      ],
      "id": "471da0c0-c060-4271-bd78-2550a52a6a16",
      "name": "Auto-fixing Output Parser"
    },
    {
      "parameters": {
        "inputSource": "jsonExample",
        "jsonExample": "{\n\"theme\": \"a string\",\n\"duration\": 5,\n\"level\": \"a string\",\n\"mode\": \"a string\"  ,\n\"imageStyle\": \"a string\",\n\"scenes\": 2,\n\"targetWordsPerParagraph\":20\n}"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        64,
        0
      ],
      "id": "1683c033-a3c0-4d8e-b36d-9ea0d72a0f1d",
      "name": "START"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=text: {{ $('AI Narrator Text Generator').item.json.output }}\nimageStyle:{{ $('START').item.json.imageStyle }}\nscenes:{{ $('START').item.json.scenes }}\ntargetWordsPerParagraph:{{ $('START').item.json.targetWordsPerParagraph }}\navailableVoices: {{ JSON.stringify($('@GLOBAL_SHADOWING').item.json.AVAILABLE_VOICES) }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=# System Prompt — Scene Segmentation & Visual Description Agent (Updated)\n\nYou are an agent that **receives a long text** and an **image style**, and returns a **structured JSON** that:\n1. **Splits the text into coherent scenes** (narrative or thematic units).\n2. For **each scene**, produces a **detailed image description** (following the requested style: *realistic, 3D, anime, cartoon, etc.*).\n3. **Groups the original paragraphs** that belong to each scene, **preserving order** and recording their original indices.\n4. Marks whether a scene is an **introduction** via the boolean field `introduction`.\n\n---\n\n## Inputs\n- `text` (string): the full text to process.\n- `imageStyle` (string): one of `{realistic | 3d | anime | cartoon | illustration | painting | lowpoly | pixelart | manga | photographic}` (accept variations in case/accents; normalize internally).\n- `maxSceneLength` (optional, integer): suggested approximate maximum length per scene (in paragraphs). Treat it as a **hint**, not a rigid rule.\n- `sceneCount` (optional, integer): **target number of scenes**. When provided, **produce exactly this number of scenes** while keeping semantic coherence.\n- `availableVoices` (array of objects): e.g.  \n  `[{\"voiceId\":\"ChO6kqkVouUn0s7HMunx\",\"description\":\"middle-aged male\"},{\"voiceId\":\"4YYIPFl9wE5c4L2eu2Gb\",\"description\":\"deep strong male narrator voice\"},{\"voiceId\":\"SAz9YHcvj6GT2YYXdXww\",\"description\":\"middle-aged female\"},{\"voiceId\":\"ZF6FPAbjXT4488VcRRnw\",\"description\":\"teenage female\"}]`\n\n---\n\n## Scene Segmentation Rules\n1. **Intro scene (mandatory, synthesized)**:\n   - **Scene 0** is **always** an introduction with **exactly one paragraph** and `introduction: true`.\n   - **This paragraph is GENERATED by the agent** (it does **not** come from the original text paragraphs).\n   - Content requirements (keep concise, 1–3 sentences):\n     - **State the theme of the shadowing text** (extract the most fitting theme from the full input; e.g., “Theme: directions in a historical town.”).\n     - Explain the **3-pass method** for shadowing: **(1)** first pass, the user **listens** attentively; **(2)** second pass, the user **repeats after**; **(3)** third pass, the user **speaks together**.\n     - Add a brief **encouragement** line (e.g., “breathe, articulate clearly, and keep pace”).\n   - Language of the intro must **match the input language**.\n   - The image description for scene 0 should be a **neutral title-card visual** consistent with `imageStyle` (no brands/logos).\n   - **Paragraph mapping for scene 0**: use a single synthetic paragraph object with `\"id\": -1`, the generated `\"text\"`, and an assigned `\"voiceId\"` (prefer a narrator voice if available).\n2. **Semantic criterion (remaining scenes)**: create a new scene when there is a clear change of **location**, **time**, **character focus**, **event**, or **subtopic**.\n3. **Internal cohesion**: each scene must form a cohesive unit; avoid one-paragraph scenes unless there is a clear shift (note: scene 0 is intentionally one paragraph).\n4. **Full coverage of original text**: every **original** paragraph from the input must belong to **exactly one** scene **from index ≥ 1**. **Do not omit** paragraphs.\n5. **Preserve order**: scenes and paragraphs within each scene must follow the original order.\n6. **Granularity**: prefer **fewer, well-defined scenes** over excessive fragmentation. Use `maxSceneLength` only as guidance.\n7. **Targeted distribution (when `sceneCount` is provided)**: distribute **original** paragraphs across exactly `sceneCount` scenes so that:\n   - All scenes are **non-empty** (scene 0 is the synthetic intro; the remaining `sceneCount-1` scenes must cover all original paragraphs).\n   - Scene sizes are **balanced** (difference of at most one paragraph where possible).\n   - **Semantic boundaries** are respected first; when semantics and exact balancing conflict, **merge or slightly shift** adjacent boundaries to achieve both coherence and the requested count.\n   - **Keep scene 0 fixed** as the intro with one synthetic paragraph.\n\n---\n\n## Image Description (per scene)\nProduce a **single** description per scene in clear, objective language, suitable for image generation. Follow:\n- **Style**: explicitly integrate `imageStyle` (e.g., “anime style”, “physically-based 3D render”, “realistic 50mm photography”, etc.).\n- **Visual content**: include **primary subjects**, **action/pose**, **setting/environment**, **lighting**, **color palette**, **composition/framing**, **mood/atmosphere**, and **level of detail**.\n- **Caption-friendly composition (required)**: the image must be **simple and uncluttered** to support an overlaid caption. **Avoid** dense textures, fine or busy line-work, heavy patterns, excessive micro-detail, or visual noise. Prefer **clean shapes**, **ample negative space**, **stable backgrounds** with **moderate contrast**, and a clear focal area that **does not compete** with the caption.\n- **ABSOLUTE RESTRICTION**: **no text in the image, ever**. The **description must explicitly include** a clear instruction such as **“no text in the image”**.\n- **Restrictions**: do not inject proper names or facts **not present** in the text; **no** brands/logos; **do not** copy non-visual sentences from the text.\n- **Intro scene hint**: prefer a clean **title card** or abstract motif related to the theme and the 3-pass method (generic icons like headphones or sound waves are acceptable and neutral).\n\n---\n\n## Paragraph Mapping\n- Split `text` into paragraphs using **blank lines** as separators (or `\\n\\n` where applicable).\n- **Scene 0 (synthetic)**:\n  - `paragraphs` contains **one** object:  \n    `{ \"id\": -1, \"text\": \"<generated intro per rules>\", \"voiceId\": \"<assigned from availableVoices (prefer narrator)>\" }`.\n- **Scenes 1..k (original text only)**:\n  - For each scene, return an array `paragraphs` of objects:\n    - `id` (integer): the **global** paragraph index in the original text, starting at 0.\n    - `text` (string): the **exact** original paragraph content (no rewriting).\n    - `voiceId` (string): **must** be assigned from one of the entries in `availableVoices` according to the **Voice Assignment Rules** below.\n- **Do not alter** punctuation, diacritics, or capitalization of original paragraphs.\n- target Words Per Paragraph: targetWordsPerParagraph\n\n---\n\n## Voice Assignment Rules\nSelect `voiceId` **per paragraph** using `availableVoices`. Use semantics to guide assignment:\n- **Narration / neutral exposition**: prefer `\"deep strong male narrator voice\"` (`voiceId: \"4YYIPFl9wE5c4L2eu2Gb\"`) or another clearly “narrator” voice if provided.\n- **Adult male speaker**: prefer `\"middle-aged male\"` (`\"ChO6kqkVouUn0s7HMunx\"`).\n- **Adult female speaker**: prefer `\"middle-aged female\"` (`\"SAz9YHcvj6GT2YYXdXww\"`).\n- **Teen/younger speaker**: prefer `\"teenage female\"` (`\"ZF6FPAbjXT4488VcRRnw\"`).\n- In **dialogues**, alternate voices consistent with speaker identity; keep a **single voice per paragraph**.\n- If ambiguity remains, default to the **narrator** voice for continuity.\n\n---\n\n## Required Validations\n- **Coverage of original text**: across scenes with `index ≥ 1`, all `id` indices must be **contiguous** and cover **0..N-1** with no gaps or duplicates.\n- **Exclusion of synthetic intro from coverage**: the paragraph with `id: -1` in scene 0 is **synthetic** and **must not** appear in the 0..N-1 range.\n- Each paragraph (original) must belong to **only one** scene (index ≥ 1).\n- `scenes` must not be empty.\n- **Scene 0**:\n  - `index === 0`\n  - `introduction === true`\n  - `paragraphs.length === 1` with `id === -1` and a valid `voiceId`.\n- **Scenes 1..k**:\n  - `introduction === false`\n  - each contains **at least one** original paragraph and each paragraph has a valid `voiceId` from `availableVoices`.\n- If `sceneCount` is provided, the length of `scenes` **must equal** `sceneCount`.\n\n---\n\n## Output (format and JSON only)\nReturn **only** a valid JSON following **exactly** this structure:\n\n```json\n{\n  \"imageStyle\": \"normalized-string\",\n  \"scenes\": [\n    {\n      \"index\": 0,\n      \"introduction\": true,\n      \"description\": \"detailed image prompt for the intro/title-card, aligned with imageStyle; include explicit instruction: no text in the image\",\n      \"paragraphs\": [\n        { \"id\": -1, \"text\": \"Theme: <auto-extracted theme>. Shadowing in 3 passes — first, listen attentively; second, repeat after the reading; third, speak together. Keep a steady pace, breathe, and articulate clearly.\", \"voiceId\": \"<from availableVoices (prefer narrator)>\" }\n      ]\n    },\n    {\n      \"index\": 1,\n      \"introduction\": false,\n      \"description\": \"detailed image prompt for the scene, aligned with imageStyle; include explicit instruction: no text in the image\",\n      \"paragraphs\": [\n        { \"id\": 0, \"text\": \"...\", \"voiceId\": \"<from availableVoices>\" },\n        { \"id\": 1, \"text\": \"...\", \"voiceId\": \"<from availableVoices>\" }\n      ]\n    }\n  ]\n}\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        752,
        0
      ],
      "id": "04f44f7a-6b2f-4cdd-81ce-6227260bf7fa",
      "name": "AI Scenes Generator"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=theme: {{ $('START').item.json.theme }}\nduration: {{ $('START').item.json.duration }} min\nlevel: {{ $('START').item.json.level }}\nmode: {{ $('START').item.json.mode }}\ntargetWordsByParagraph: {{ $('START').item.json.targetWordsPerParagraph }}",
        "options": {
          "systemMessage": "=# System Prompt — English Shadowing Agent (Colon Allowed, No Quotes)\n\nRole\nYou generate practice material for English shadowing. You must write a text that fits the requested duration level and mode while using the linguistic targets specified in THEME. The text is for immediate repetition shadowing with rhythm and intonation. Do not explain grammar inside the main text.\n\nCharacter Set Constraint\nOutput must contain only ASCII letters numbers spaces line breaks and the colon character\n- Allowed A to Z a to z 0 to 9 space line break and colon :\n- Disallowed any other punctuation including quotes commas periods question marks exclamation marks apostrophes parentheses brackets slashes underscores dashes bullets currency and math symbols\n- No markdown\n\nRequired Inputs\n- THEME linguistic targets to be used in the text not discussed Examples\n  simple past plus present perfect\n  there is there are present and past plus some any\n  comparatives and superlatives plus too enough\n  phrasal verbs get up look for figure out\n- DURATION_MIN target reading time in minutes for example 2 3 8\n- LEVEL optional A1 to C1 Default B1 B2\n- MODE optional presentation format Allowed values\n  dialogue\n  narrative\n  expository\n  persuasive\nIf MODE is omitted choose dialogue for everyday contexts and expository for technical themes\n- targetWordsByParagraph optional integer Soft minimum number of words per paragraph or speaker turn Keep each paragraph or line at or above this number within plus or minus 10 percent unless coherence would break\n\nTheme And Mode Rules\n1 THEME equals linguistic targets to appear in the text The text must demonstrate these forms naturally and repeatedly with varied contexts Do not define or teach them inside the main text If clarification is needed provide a mini glossary after the text also respecting the character set constraint\n2 MODE equals how the content is presented If MODE equals narrative produce a short story about someone that uses the targets from THEME\n\nTiming And Density\n- Target reading speed words per minute by level\n  A2 equals 110 plus or minus 10\n  B1 B2 equals 140 plus or minus 10 default\n  C1 equals 160 plus or minus 10\n- Text length calculation\n  TARGET_WORDS equals level wpm times DURATION_MIN times 0 90\n  The 0 90 factor reserves about 10 percent for natural pauses\n- Duration tolerance plus or minus 10 percent of the target time\n\nDialogue Labeling With Colon Only\n- When there is more than one character label each turn as Personagem Name colon space then the utterance without quotes\n  Example\n  Mother: I was late but I have finished the task\n  Son: did you finish it or have you just started it\n- Use only the colon as punctuation Nothing else\n- Keep each speaker turn at or above targetWordsByParagraph within plus or minus 10 percent unless this harms clarity\n\nLanguage Guidelines\n- Use 85 to 95 percent high frequency vocabulary for the target level The rest may introduce topic terms made clear by context\n- Use short lines and clear segmentation across line breaks Since other punctuation is not allowed rely on line breaks and simple clause chains\n- Include connected speech reductions when natural and within the constraint for example gonna wanna gotta\n- American accent No sensitive or inappropriate content\n- Vary openings and cadence Alternate statements and questions using cue words and word order only\n\nOutput Format\n- Raw simple text with only allowed characters\n- Organize the text in short lines for breath control\n- After the main text you may include an optional Glossary with up to five entries Each entry must use only allowed characters Format word colon space meaning across lines\n  Example\n  repair: fix\n  borrow: take for a time\n\nContent Construction Checklist\n1 Map THEME to usage patterns Spread them across the text with multiple occurrences Mix affirmative negative and interrogative forms using cue words\n2 Honor MODE strictly\n  Dialogue alternating speaker lines with Personagem Name colon space utterance without quotes\n  Narrative clear scene character and action\n  Expository simple progression with concrete examples\n  Persuasive claim reason example call to action\n3 Maintain shadowing flow vary length and use line breaks\n4 Keep topical coherence and natural contexts for the targets\n5 Enforce targetWordsByParagraph as a soft minimum per paragraph or speaker turn within plus or minus 10 percent\n\nExamples Of Input To Output Framing\n- THEME simple past plus present perfect and MODE narrative produce a story about someone that uses both tenses across finished actions and present results\n- THEME there is there are present and past plus some any and MODE dialogue produce a conversation that uses availability and existence patterns\n\nEdge Cases\n- If THEME contains conflicting or advanced targets for the LEVEL prioritize clarity reduce density and keep duration\n- Do not include metalinguistic commentary in the main text Place any notes only in the Glossary using allowed characters\n\nDeliverables\n1 Main text that uses all targets from THEME according to MODE matching TARGET_WORDS\n2 Optional Glossary with up to five entries\n3 Nothing else\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        448,
        0
      ],
      "id": "a1e39061-c1a4-458c-bd22-e22b0cd74a67",
      "name": "AI Narrator Text Generator"
    },
    {
      "parameters": {
        "jsCode": "// Retorna um array de itens n8n, um por cena: [{ json: scene }, ...]\nconst out = [];\n\nfor (const item of items) {\n  const root = Array.isArray(item.json) ? item.json[0] : item.json;\n  const scenes = root?.output?.scenes ?? [];\n  for (const scene of scenes) out.push({ json: scene });\n}\n\nreturn out;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1072,
        0
      ],
      "id": "193d6ef3-c9be-4601-b3d3-69b6f7dc2382",
      "name": "Splice scenes"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "VdmO0DZ3i6iBFRiU",
          "mode": "list",
          "cachedResultUrl": "/workflow/VdmO0DZ3i6iBFRiU",
          "cachedResultName": "@GLOBAL_SHADOWING"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {}
        },
        "options": {}
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        240,
        0
      ],
      "id": "e1c0138c-f6ed-4a29-a2b5-1e4ea2ece265",
      "name": "@GLOBAL_SHADOWING"
    }
  ],
  "connections": {
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Narrator Text Generator",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "AI Scenes Generator",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Auto-fixing Output Parser",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Auto-fixing Output Parser",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Auto-fixing Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "AI Scenes Generator",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "START": {
      "main": [
        [
          {
            "node": "@GLOBAL_SHADOWING",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Scenes Generator": {
      "main": [
        [
          {
            "node": "Splice scenes",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Narrator Text Generator": {
      "main": [
        [
          {
            "node": "AI Scenes Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Splice scenes": {
      "main": [
        []
      ]
    },
    "@GLOBAL_SHADOWING": {
      "main": [
        [
          {
            "node": "AI Narrator Text Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {
    "START": [
      {
        "json": {
          "theme": "Passado simples, participio passado e passado continuo",
          "duration": 3,
          "level": "B2",
          "mode": "Diálogo fictício de um estudante contato para sua mãe sobre como foi a aula do dia",
          "imageStyle": "Anime estilo 3D",
          "scenes": 4,
          "targetWordsPerParagraph": 45
        }
      }
    ]
  },
  "versionId": "907e2919-0a88-401a-80c2-51470820a82c",
  "triggerCount": 0,
  "shared": [
    {
      "createdAt": "2025-10-16T23:18:04.775Z",
      "updatedAt": "2025-10-16T23:18:04.775Z",
      "role": "workflow:owner",
      "workflowId": "Hg91NZVyqdB46nko",
      "projectId": "TH7SrF7Rx9ho2z9i",
      "project": {
        "createdAt": "2025-08-20T20:52:17.088Z",
        "updatedAt": "2025-08-20T20:53:20.326Z",
        "id": "TH7SrF7Rx9ho2z9i",
        "name": "Hugo Dutra <hugo.dutra@hotmail.com>",
        "type": "personal",
        "icon": null,
        "description": null,
        "projectRelations": [
          {
            "createdAt": "2025-08-20T20:52:17.089Z",
            "updatedAt": "2025-08-20T20:52:17.089Z",
            "userId": "96b62bee-ebb1-4fe5-a51b-c116ef7064eb",
            "projectId": "TH7SrF7Rx9ho2z9i",
            "user": {
              "createdAt": "2025-08-20T20:52:15.066Z",
              "updatedAt": "2025-10-27T11:31:02.000Z",
              "id": "96b62bee-ebb1-4fe5-a51b-c116ef7064eb",
              "email": "hugo.dutra@hotmail.com",
              "firstName": "Hugo",
              "lastName": "Dutra",
              "personalizationAnswers": {
                "version": "v4",
                "personalization_survey_submitted_at": "2025-08-20T20:56:08.200Z",
                "personalization_survey_n8n_version": "1.107.4",
                "automationGoalDevops": [
                  "other"
                ],
                "automationGoalDevopsOther": "Video As A Service",
                "companySize": "<20",
                "companyType": "saas",
                "role": "engineering",
                "reportedSource": "youtube"
              },
              "settings": {
                "userActivated": true,
                "firstSuccessfulWorkflowId": "DOfnd0M834V8kbv2",
                "userActivatedAt": 1755725592234,
                "npsSurvey": {
                  "responded": true,
                  "lastShownAt": 1757188846991
                },
                "easyAIWorkflowOnboarded": true,
                "dismissedCallouts": {
                  "preBuiltAgentsCalloutHttpRequest": true,
                  "preBuiltAgentsModalCallout": true
                }
              },
              "disabled": false,
              "mfaEnabled": false,
              "lastActiveAt": "2025-10-27",
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": []
}