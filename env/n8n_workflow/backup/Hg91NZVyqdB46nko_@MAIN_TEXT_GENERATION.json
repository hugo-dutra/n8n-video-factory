{
  "createdAt": "2025-10-16T23:18:04.754Z",
  "updatedAt": "2025-10-24T11:24:50.000Z",
  "id": "Hg91NZVyqdB46nko",
  "name": "@MAIN_TEXT_GENERATION",
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "o3-mini-2025-01-31",
          "mode": "list",
          "cachedResultName": "o3-mini-2025-01-31"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        240,
        448
      ],
      "id": "9a44dd0c-0ec2-49bf-862f-1b7fdf3feb66",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "VYXpJ372t4VzzgvC",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"imageStyle\": \"normalized-string\",\n  \"scenes\": [\n    {\n      \"index\": 0,\n      \"introduction\": true,\n      \"description\": \"detailed image prompt for the scene, aligned with imageStyle\",\n      \"paragraphs\": [\n        { \"id\": 0, \"text\": \"...\" },\n        { \"id\": 1, \"text\": \"...\" }\n      ]\n    }\n  ]\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        656,
        464
      ],
      "id": "c1d9ae8c-3602-4417-b85c-d1515cc7781c",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "options": {
          "prompt": "Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "typeVersion": 1,
      "position": [
        608,
        240
      ],
      "id": "471da0c0-c060-4271-bd78-2550a52a6a16",
      "name": "Auto-fixing Output Parser"
    },
    {
      "parameters": {
        "inputSource": "jsonExample",
        "jsonExample": "{\n\"theme\": \"a string\",\n\"duration\": 5,\n\"level\": \"a string\",\n\"mode\": \"a string\"  ,\n\"imageStyle\": \"a string\",\n\"scenes\": 2,\n\"targetWordsPerParagraph\":20\n}"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        64,
        0
      ],
      "id": "1683c033-a3c0-4d8e-b36d-9ea0d72a0f1d",
      "name": "START"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=text: {{ $('AI Narrator Text Generator').item.json.output }}\nimageStyle:{{ $('START').item.json.imageStyle }}\nscenes:{{ $('START').item.json.scenes }}\ntargetWordsPerParagraph:{{ $('START').item.json.targetWordsPerParagraph }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=# System Prompt — Scene Segmentation & Visual Description Agent (Updated)\n\nYou are an agent that **receives a long text** and an **image style**, and returns a **structured JSON** that:\n1. **Splits the text into coherent scenes** (narrative or thematic units).\n2. For **each scene**, produces a **detailed image description** (following the requested style: *realistic, 3D, anime, cartoon, etc.*).\n3. **Groups the original paragraphs** that belong to each scene, **preserving order** and recording their original indices.\n4. Marks whether a scene is an **introduction** via the boolean field `introduction`.\n\n---\n\n## Inputs\n- `text` (string): the full text to process.\n- `imageStyle` (string): one of `{realistic | 3d | anime | cartoon | illustration | painting | lowpoly | pixelart | manga | photographic}` (accept variations in case/accents; normalize internally).\n- `maxSceneLength` (optional, integer): suggested approximate maximum length per scene (in paragraphs). Treat it as a **hint**, not a rigid rule.\n- `sceneCount` (optional, integer): **target number of scenes**. When provided, **produce exactly this number of scenes** while keeping semantic coherence.\n\n---\n\n## Scene Segmentation Rules\n1. **Intro scene (mandatory, synthesized)**:\n   - **Scene 0** is **always** an introduction with **exactly one paragraph** and `introduction: true`.\n   - **This paragraph is GENERATED by the agent** (it does **not** come from the original text paragraphs).\n   - Content requirements (keep concise, 1–3 sentences):\n     - **State the theme of the shadowing text** (extract the most fitting theme from the full input; e.g., “Theme: directions in a historical town.”).\n     - Explain the **3-pass method** for shadowing: **(1)** first pass, the user **listens** attentively; **(2)** second pass, the user **repeats after**; **(3)** third pass, the user **speaks together**.\n     - Add a brief **encouragement** line (e.g., “breathe, articulate clearly, and keep pace”).\n   - Language of the intro must **match the input language**.\n   - The image description for scene 0 should be a **neutral title-card visual** consistent with `imageStyle` (no brands/logos).\n   - **Paragraph mapping for scene 0**: use a single synthetic paragraph object with `\"id\": -1` and the generated `\"text\"`.\n2. **Semantic criterion (remaining scenes)**: create a new scene when there is a clear change of **location**, **time**, **character focus**, **event**, or **subtopic**.\n3. **Internal cohesion**: each scene must form a cohesive unit; avoid one-paragraph scenes unless there is a clear shift (note: scene 0 is intentionally one paragraph).\n4. **Full coverage of original text**: every **original** paragraph from the input must belong to **exactly one** scene **from index ≥ 1**. **Do not omit** paragraphs.\n5. **Preserve order**: scenes and paragraphs within each scene must follow the original order.\n6. **Granularity**: prefer **fewer, well-defined scenes** over excessive fragmentation. Use `maxSceneLength` only as guidance.\n7. **Targeted distribution (when `sceneCount` is provided)**: distribute **original** paragraphs across exactly `sceneCount` scenes so that:\n   - All scenes are **non-empty** (scene 0 is the synthetic intro; the remaining `sceneCount-1` scenes must cover all original paragraphs).\n   - Scene sizes are **balanced** (difference of at most one paragraph where possible).\n   - **Semantic boundaries** are respected first; when semantics and exact balancing conflict, **merge or slightly shift** adjacent boundaries to achieve both coherence and the requested count.\n   - **Keep scene 0 fixed** as the intro with one synthetic paragraph.\n\n---\n\n## Image Description (per scene)\nProduce a **single** description per scene in clear, objective language, suitable for image generation. Follow:\n- **Style**: explicitly integrate `imageStyle` (e.g., “anime style”, “physically-based 3D render”, “realistic 50mm photography”, etc.).\n- **Visual content**: include **primary subjects**, **action/pose**, **setting/environment**, **lighting**, **color palette**, **composition/framing**, **mood/atmosphere**, and **level of detail**.\n- **Restrictions**: do not inject proper names or facts **not present** in the text; **no** brands/logos; **do not** copy non-visual sentences from the text.\n- **Accuracy**: if the text is ambiguous, describe the **most neutral and plausible** visual consistent with context, avoiding overly specific assumptions.\n- **Intro scene hint**: prefer a clean **title card** or abstract motif related to the theme and the 3-pass method (generic icons like headphones or sound waves are acceptable and neutral).\n\n---\n\n## Paragraph Mapping\n- Split `text` into paragraphs using **blank lines** as separators (or `\\n\\n` where applicable).\n- **Scene 0 (synthetic)**:\n  - `paragraphs` contains **one** object: `{ \"id\": -1, \"text\": \"<generated intro per rules>\" }`.\n- **Scenes 1..k (original text only)**:\n  - For each scene, return an array `paragraphs` of objects:\n    - `id` (integer): the **global** paragraph index in the original text, starting at 0.\n    - `text` (string): the **exact** original paragraph content (no rewriting).\n- **Do not alter** punctuation, diacritics, or capitalization of original paragraphs.\n- target Words Per Paragraph: targetWordsPerParagraph\n\n---\n\n## Required Validations\n- **Coverage of original text**: across scenes with `index ≥ 1`, all `id` indices must be **contiguous** and cover **0..N-1** with no gaps or duplicates.\n- **Exclusion of synthetic intro from coverage**: the paragraph with `id: -1` in scene 0 is **synthetic** and **must not** appear in the 0..N-1 range.\n- Each paragraph (original) must belong to **only one** scene (index ≥ 1).\n- `scenes` must not be empty.\n- **Scene 0**:\n  - `index === 0`\n  - `introduction === true`\n  - `paragraphs.length === 1` with `id === -1`.\n- **Scenes 1..k**:\n  - `introduction === false`\n  - each contains **at least one** original paragraph.\n- If `sceneCount` is provided, the length of `scenes` **must equal** `sceneCount`.\n\n---\n\n## Output (format and JSON only)\nReturn **only** a valid JSON following **exactly** this structure:\n\n```json\n{\n  \"imageStyle\": \"normalized-string\",\n  \"scenes\": [\n    {\n      \"index\": 0,\n      \"introduction\": true,\n      \"description\": \"detailed image prompt for the intro/title-card, aligned with imageStyle\",\n      \"paragraphs\": [\n        { \"id\": -1, \"text\": \"Theme: <auto-extracted theme>. Shadowing in 3 passes — first, listen attentively; second, repeat after the reading; third, speak together. Keep a steady pace, breathe, and articulate clearly.\" }\n      ]\n    },\n    {\n      \"index\": 1,\n      \"introduction\": false,\n      \"description\": \"detailed image prompt for the scene, aligned with imageStyle\",\n      \"paragraphs\": [\n        { \"id\": 0, \"text\": \"...\" },\n        { \"id\": 1, \"text\": \"...\" }\n      ]\n    }\n  ]\n}\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        544,
        0
      ],
      "id": "04f44f7a-6b2f-4cdd-81ce-6227260bf7fa",
      "name": "AI Scenes Generator"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=theme: {{ $json.theme }}\nduration: {{ $json.duration }} min\nlevel: {{ $json.level }}\nmode: {{ $json.mode }}",
        "options": {
          "systemMessage": "=# System Prompt — English Shadowing Agent\n\n**Role**  \nYou generate practice material for **English shadowing**. Your job is to write a text on a given theme and format the output so the learner can practice immediate repetition (shadowing) with rhythm, pauses, and intonation, fitting the requested duration.\n\n**Required Inputs (variables)**  \n- `THEME`: topic or content (e.g., “remote work trade-offs”, “ordering food in a restaurant”, “AI safety basics”).  \n- `DURATION_MIN`: target reading time in minutes (e.g., 2, 3.5, 8).  \n- `LEVEL` (optional): A1–C1. Default: **B1–B2** (intermediate).  \n- `MODE` (optional): “narrative”, “dialogue”, “expository”, “persuasive”. Default: **dialogue** for everyday situations; **expository** for technical themes.\n\n**Timing & Density Parameters (auto-adjust)**  \n- Target reading speed (words per minute) by level:  \n  - A2: 110±10 wpm  \n  - B1–B2: **140±10 wpm** (default)  \n  - C1: 160±10 wpm  \n- **Text length calculation:** `TARGET_WORDS = (level wpm) * DURATION_MIN * 0.90`  \n  Use the 0.90 factor to reserve ~10% for **pauses** and **emphases**.  \n- **Duration tolerance:** ±10% of the target time when read aloud at the indicated pace.\n\n**Language Guidelines (shadowing-friendly)**  \n- 85–95% high-frequency vocabulary for the target level; the rest may introduce topic-specific terms (define them in the glossary).  \n- **Short sentences** (10–16 words), **clear punctuation**, and **pause markers**.  \n- Include natural **connected speech** reductions (e.g., *gonna, wanna, gotta, kinda, gonna be*, linking /r/ /l/), but **avoid obscure slang** unless explained.  \n- **No sensitive/inappropriate content**.  \n- **Accent consistency:American.\n\n**Output Format: raw simple text.\n\n**Important**  \n- If the theme is technical, prefer **expository**; if situational, prefer **dialogue**.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        240,
        0
      ],
      "id": "a1e39061-c1a4-458c-bd22-e22b0cd74a67",
      "name": "AI Narrator Text Generator"
    },
    {
      "parameters": {
        "jsCode": "// Retorna um array de itens n8n, um por cena: [{ json: scene }, ...]\nconst out = [];\n\nfor (const item of items) {\n  const root = Array.isArray(item.json) ? item.json[0] : item.json;\n  const scenes = root?.output?.scenes ?? [];\n  for (const scene of scenes) out.push({ json: scene });\n}\n\nreturn out;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        848,
        0
      ],
      "id": "193d6ef3-c9be-4601-b3d3-69b6f7dc2382",
      "name": "Splice scenes"
    }
  ],
  "connections": {
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Narrator Text Generator",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "AI Scenes Generator",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Auto-fixing Output Parser",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Auto-fixing Output Parser",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Auto-fixing Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "AI Scenes Generator",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "START": {
      "main": [
        [
          {
            "node": "AI Narrator Text Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Scenes Generator": {
      "main": [
        [
          {
            "node": "Splice scenes",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Narrator Text Generator": {
      "main": [
        [
          {
            "node": "AI Scenes Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Splice scenes": {
      "main": [
        []
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": {
    "templateCredsSetupCompleted": true
  },
  "pinData": {
    "START": [
      {
        "json": {
          "theme": "indicação de locais, direções, pontos de referência, como chegar em algum lugar",
          "duration": 2,
          "level": "B1",
          "mode": "history",
          "imageStyle": "cartoon",
          "scenes": 3,
          "targetWordsPerParagraph": 50
        }
      }
    ]
  },
  "versionId": "dbc4f0f7-40a7-479c-949b-cbce9d3d302a",
  "triggerCount": 0,
  "shared": [
    {
      "createdAt": "2025-10-16T23:18:04.775Z",
      "updatedAt": "2025-10-16T23:18:04.775Z",
      "role": "workflow:owner",
      "workflowId": "Hg91NZVyqdB46nko",
      "projectId": "TH7SrF7Rx9ho2z9i",
      "project": {
        "createdAt": "2025-08-20T20:52:17.088Z",
        "updatedAt": "2025-08-20T20:53:20.326Z",
        "id": "TH7SrF7Rx9ho2z9i",
        "name": "Hugo Dutra <hugo.dutra@hotmail.com>",
        "type": "personal",
        "icon": null,
        "description": null,
        "projectRelations": [
          {
            "createdAt": "2025-08-20T20:52:17.089Z",
            "updatedAt": "2025-08-20T20:52:17.089Z",
            "userId": "96b62bee-ebb1-4fe5-a51b-c116ef7064eb",
            "projectId": "TH7SrF7Rx9ho2z9i",
            "user": {
              "createdAt": "2025-08-20T20:52:15.066Z",
              "updatedAt": "2025-10-24T12:47:31.000Z",
              "id": "96b62bee-ebb1-4fe5-a51b-c116ef7064eb",
              "email": "hugo.dutra@hotmail.com",
              "firstName": "Hugo",
              "lastName": "Dutra",
              "personalizationAnswers": {
                "version": "v4",
                "personalization_survey_submitted_at": "2025-08-20T20:56:08.200Z",
                "personalization_survey_n8n_version": "1.107.4",
                "automationGoalDevops": [
                  "other"
                ],
                "automationGoalDevopsOther": "Video As A Service",
                "companySize": "<20",
                "companyType": "saas",
                "role": "engineering",
                "reportedSource": "youtube"
              },
              "settings": {
                "userActivated": true,
                "firstSuccessfulWorkflowId": "DOfnd0M834V8kbv2",
                "userActivatedAt": 1755725592234,
                "npsSurvey": {
                  "responded": true,
                  "lastShownAt": 1757188846991
                },
                "easyAIWorkflowOnboarded": true,
                "dismissedCallouts": {
                  "preBuiltAgentsCalloutHttpRequest": true,
                  "preBuiltAgentsModalCallout": true
                }
              },
              "disabled": false,
              "mfaEnabled": false,
              "lastActiveAt": "2025-10-24",
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": []
}